{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Открываем тренировочную и тестовую выборку ПЕРВОГО датасета**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS1train = pd.read_csv('dataset1_train_11414r_without_sw_pnct.csv',encoding='utf-8')\n",
    "DS1train_without_numbers = pd.DataFrame(columns=['comment', 'toxic'])\n",
    "\n",
    "DS1test = pd.read_csv('dataset1_test_2999r_without_sw_pnct.csv',encoding='utf-8')\n",
    "DS1test_without_numbers = pd.DataFrame(columns=['comment', 'toxic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Открываем тренировочную и тестовую выборку ВТОРОГО датасета**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS2train = pd.read_csv('dataset2_train_126834r_without_sw_pnct.csv',encoding='utf-8')\n",
    "DS2train_without_numbers = pd.DataFrame(columns=['comment', 'toxic'])\n",
    "\n",
    "DS2test = pd.read_csv('dataset2_test_100000r_without_sw_pnct.csv',encoding='utf-8')\n",
    "DS2test_without_numbers = pd.DataFrame(columns=['comment', 'toxic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Функция для чистки датасетов от цифр**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_me(comment):\n",
    "    tokens=nltk.word_tokenize(comment.lower())\n",
    "\n",
    "    st=''\n",
    "    for k in range(len(tokens)):\n",
    "        if  not tokens[k].isdigit():\n",
    "            st+=tokens[k]+' '\n",
    "    \n",
    "    return st.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проводим чистку тренировочной и тестовой выборки из ПЕРВОГО датасета от цифр**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(DS1train.index.size):\n",
    "    clean_str=tokenize_me(DS1train['comment'][i])\n",
    "    DS1train_without_numbers=DS1train_without_numbers.append({'comment':clean_str,'toxic': str(DS1train['toxic'][i])},ignore_index=True)\n",
    "\n",
    "for j in range(DS1test.index.size):\n",
    "    clean_str=tokenize_me(DS1test['comment'][j])\n",
    "    DS1test_without_numbers=DS1test_without_numbers.append({'comment': clean_str,'toxic':str(DS1test['toxic'][j])},ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проводим чистку тренировочной и тестовой выборки из ВТОРОГО датасета от цифр**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(DS2train.index.size):\n",
    "    clean_str=tokenize_me(DS2train['comment'][i])\n",
    "    DS2train_without_numbers=DS2train_without_numbers.append({'comment':clean_str,'toxic': str(DS2train['toxic'][i])},ignore_index=True)\n",
    "\n",
    "for j in range(DS2test.index.size):\n",
    "    clean_str=tokenize_me(DS2test['comment'][j])\n",
    "    DS2test_without_numbers=DS2test_without_numbers.append({'comment': clean_str,'toxic':str(DS2test['toxic'][j])},ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сохроняем очищенные данные тренировочной и тестовой выборки из ПЕРВОГО датасета**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset1_train_11414r_without_sw_pnct_ns.csv','w',encoding='utf8') as DS1train_inf:\n",
    "    DS1train_inf.write(\"comment,toxic\"+'\\n')\n",
    "    for i in range(DS1train.index.size):\n",
    "        if not ( DS1train_without_numbers['comment'][i] == '' ):\n",
    "            DS1train_inf.write('\\\"'+DS1train_without_numbers['comment'][i]+'\\\"'+','+'\\\"'+DS1train_without_numbers['toxic'][i]+'\\\"'+'\\n')\n",
    "            \n",
    "with open('dataset1_test_2999r_without_sw_pnct_ns.csv','w',encoding='utf8') as DS1test_inf:\n",
    "    DS1test_inf.write(\"comment,toxic\"+'\\n')\n",
    "    for j in range(DS1test.index.size):\n",
    "        if not ( DS1test_without_numbers['comment'][j] == '' ):\n",
    "            DS1test_inf.write('\\\"'+DS1test_without_numbers['comment'][j]+'\\\"'+','+'\\\"'+DS1test_without_numbers['toxic'][j]+'\\\"'+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сохроняем очищенные данные тренировочной и тестовой выборки из ВТОРОГО датасета**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset2_train_126834r_without_sw_pnct_ns.csv','w',encoding='utf8') as DS2train_inf:\n",
    "    DS2train_inf.write(\"comment,toxic\"+'\\n')\n",
    "    for i in range(DS2train.index.size):\n",
    "        if not ( DS2train_without_numbers['comment'][i] == '' ):\n",
    "            DS2train_inf.write('\\\"'+DS2train_without_numbers['comment'][i]+'\\\"'+','+'\\\"'+DS2train_without_numbers['toxic'][i]+'\\\"'+'\\n')\n",
    "            \n",
    "with open('dataset2_test_100000r_without_sw_pnct_ns.csv','w',encoding='utf8') as DS2test_inf:\n",
    "    DS2test_inf.write(\"comment,toxic\"+'\\n')\n",
    "    for j in range(DS2test.index.size):\n",
    "        if not ( DS2test_without_numbers['comment'][j] == '' ):\n",
    "            DS2test_inf.write('\\\"'+DS2test_without_numbers['comment'][j]+'\\\"'+','+'\\\"'+DS2test_without_numbers['toxic'][j]+'\\\"'+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
